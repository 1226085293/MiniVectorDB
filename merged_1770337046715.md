```assembly\config.ts
/**
 * @zh-CN 配置常量
 * @en Configuration constants
 */

/**
 * @zh-CN 向量维度
 * @en Vector dimension.
 * @remarks 
 * 根据使用的模型修改此值 (Modify this based on your model):
 * - Xenova/all-MiniLM-L6-v2 (默认文本模型 Default Text): 384
 * - Xenova/clip-vit-base-patch32 (图文多模态模型 Multi-modal CLIP): 512
 * 
 * 必须是 4 的倍数以支持 SIMD 优化 (Must be a multiple of 4 for SIMD optimization).
 */
export let DIM: i32 = 384;

/**
 * @zh-CN HNSW 超参数配置
 * @en HNSW Hyperparameters configuration.
 */

/**
 * @zh-CN 图的最大层数
 * @en Maximum number of layers in the graph.
 */
export let MAX_LAYERS: i32 = 4;

/**
 * @zh-CN 每个节点在每层的最大连接数 (M)
 * @en Maximum number of connections per element per layer (M).
 */
export let M: i32 = 16;

/**
 * @zh-CN 第 0 层 (最底层) 的最大连接数
 * @en Maximum connections for layer 0 (usually 2*M).
 */
export let M_MAX0: i32 = 32;

/**
 * @zh-CN 动态候选列表的大小 (efConstruction)
 * @en Size of the dynamic candidate list for construction (efConstruction).
 * @remarks 影响构建索引时的精度和速度，值越大精度越高但构建越慢。
 * @remarks Affects the quality and speed of index construction; higher values lead to better quality but slower construction.
 */
export let EF_CONSTRUCTION: i32 = 100;

/**
 * @zh-CN 内存偏移量常量
 * @en Memory offset constants.
 * @remarks 我们使用简单的指针递增分配器，起始位置由静态数据之后决定。
 * @remarks We use a simple bump pointer allocator, with allocation starting after static data.
 */
export const NULL_PTR: i32 = 0;

/**
 * @zh-CN 更新核心配置参数。
 *         此函数必须在调用 init_index 或 insert 之前调用。
 * @en Updates the core configuration parameters.
 *       This function must be called before calling init_index or insert.
 * @param dim - 向量的维度 (Vector dimension).
 * @param m - HNSW图中每个节点的最大连接数 (Max number of connections per node in HNSW graph).
 * @param ef_construction - HNSW索引构建时动态候选列表的大小 (Size of the dynamic candidate list during HNSW index construction).
 */
export function update_config(dim: i32, m: i32, ef_construction: i32): void {
	DIM = dim;
	M = m;
	EF_CONSTRUCTION = ef_construction;
	M_MAX0 = m * 2;
}

```

---

```assembly\hnsw.ts
import { dist_l2_sq } from "./math";
import { alloc } from "./memory";
import { M, M_MAX0, EF_CONSTRUCTION, MAX_LAYERS } from "./config";
import { get_node_size, get_vector_size } from "./types";
import { CandidateList, Candidate } from "./pqueue";

// --- GLOBALS ---
let entry_point_id: i32 = -1;
let max_level: i32 = -1;
let element_count: i32 = 0;

let node_offsets_ptr: usize = 0;
let vector_storage_ptr: usize = 0;
let results_buffer_ptr: usize = 0;
let max_elements: i32 = 0;

// --- HELPERS ---
function get_node_ptr(id: i32): usize {
  return load<usize>(node_offsets_ptr + <usize>id * 4);
}
function get_vector_ptr(id: i32): usize {
  return vector_storage_ptr + <usize>id * get_vector_size();
}

export function init_index(capacity: i32): void {
  max_elements = capacity;
  node_offsets_ptr = alloc(<usize>capacity * 4);
  vector_storage_ptr = alloc(<usize>capacity * get_vector_size());
  // Allocate result buffer for max K=1000? 1000 * 8 bytes = 8KB
  // Format: [id: i32, dist: f32] * K
  results_buffer_ptr = alloc(1000 * 8);
  
  entry_point_id = -1;
  max_level = -1;
  element_count = 0;
}

function get_random_level(): i32 {
  let level: i32 = 0;
  while (Math.random() < 0.5 && level < MAX_LAYERS - 1) {
      level++;
  }
  return level;
}

// --- SEARCH LAYER ---
// Returns closest candidates found in this layer
// Used for both Insertion (finding neighbors) and Search (finding results)
function search_layer(query_vec_ptr: usize, entry_node: i32, layer: i32, ef: i32): CandidateList {
    let visited = new Set<i32>();
    let candidates = new CandidateList(ef); // Candidates to explore (Min-Heap behavior ideally, here sorted list)
    let results = new CandidateList(ef);    // Best results found so far (Max-Heap behavior ideally)
    
    let dist = dist_l2_sq(query_vec_ptr, get_vector_ptr(entry_node));
    
    visited.add(entry_node);
    candidates.push(entry_node, dist);
    results.push(entry_node, dist);
    
    while (!candidates.isEmpty()) {
        let curr = candidates.popClosest(); // Get closest candidate
        if (curr == null) break;
        
        // Optimization: if closest candidate is worse than worst result, stop?
        // Standard HNSW condition: dist > lowerBound (worst result distance)
        if (curr.distance > results.worstDist()) {
            break;
        }
        
        let curr_node_ptr = get_node_ptr(curr.id);
        
        // Move pointer to connections at 'layer'
        let runner_ptr = curr_node_ptr + 8;
        for (let l = 0; l < layer; l++) {
            let count = load<i32>(runner_ptr);
            let cap = (l == 0) ? M_MAX0 : M;
            runner_ptr += 4 + <usize>cap * 4;
        }
        
        let neighbor_count = load<i32>(runner_ptr);
        let neighbors_start = runner_ptr + 4;
        
        for (let i = 0; i < neighbor_count; i++) {
            let neighbor_id = load<i32>(neighbors_start + <usize>i * 4);
            if (!visited.has(neighbor_id)) {
                visited.add(neighbor_id);
                let d = dist_l2_sq(query_vec_ptr, get_vector_ptr(neighbor_id));
                
                // Add to results if it fits or is better than worst
                if (d < results.worstDist() || results.size() < ef) {
                    candidates.push(neighbor_id, d);
                    results.push(neighbor_id, d);
                }
            }
        }
    }
    return results;
}

// --- CONNECTION LOGIC ---
// Connect src to dst at layer. If src is full, prune.
function add_connection(src: i32, dst: i32, layer: i32): void {
    let ptr = get_node_ptr(src);
    let runner = ptr + 8;
    for (let l = 0; l < layer; l++) {
         let c = load<i32>(runner);
         let cap = (l == 0) ? M_MAX0 : M;
         runner += 4 + <usize>cap * 4;
    }
    
    let count = load<i32>(runner);
    let M_cur = (layer == 0) ? M_MAX0 : M;
    let neighbors_ptr = runner + 4;
    
    // Check if already connected (avoid duplicate)
    // Linear scan is ok for small M
    for(let i=0; i<count; i++) {
        if (load<i32>(neighbors_ptr + <usize>i*4) == dst) return;
    }

    if (count < M_cur) {
        // Just add
        store<i32>(neighbors_ptr + <usize>count * 4, dst);
        store<i32>(runner, count + 1);
    } else {
        // Full: Select Neighbors (Shrink)
        // Simple strategy: Find worst neighbor, if dst is better, replace.
        let src_vec = get_vector_ptr(src);
        let worst_idx = -1;
        let worst_dist: f32 = -1.0;
        
        // Find worst in existing
        for (let i = 0; i < count; i++) {
            let n_id = load<i32>(neighbors_ptr + <usize>i * 4);
            let d = dist_l2_sq(src_vec, get_vector_ptr(n_id));
            if (d > worst_dist) {
                worst_dist = d;
                worst_idx = i;
            }
        }
        
        let dst_dist = dist_l2_sq(src_vec, get_vector_ptr(dst));
        if (dst_dist < worst_dist) {
            // Replace
            store<i32>(neighbors_ptr + <usize>worst_idx * 4, dst);
        }
    }
}

// --- INSERT ---
export function insert(id: i32, vector_data_offset: usize): void {
    // 1. Store Vector
    let target_vec_ptr = get_vector_ptr(id);
    memory.copy(target_vec_ptr, vector_data_offset, get_vector_size());
    
    let level = get_random_level();
    
    // 2. Alloc Node
    let node_sz = get_node_size(level);
    let node_ptr = alloc(node_sz);
    store<i32>(node_ptr, id);
    store<i32>(node_ptr + 4, level);
    // Init counts
    let runner = node_ptr + 8;
    for (let l = 0; l <= level; l++) {
         store<i32>(runner, 0);
         let cap = (l == 0) ? M_MAX0 : M;
         runner += 4 + <usize>cap * 4;
    }
    store<usize>(node_offsets_ptr + <usize>id * 4, node_ptr);
    
    // 3. Insert Logic
    if (entry_point_id == -1) {
        entry_point_id = id;
        max_level = level;
        element_count++;
        return;
    }
    
    let curr_obj = entry_point_id;
    let curr_dist = dist_l2_sq(target_vec_ptr, get_vector_ptr(curr_obj));
    
    // Phase 1: Search down from max_level to level+1
    for (let l = max_level; l > level; l--) {
        let changed = true;
        while(changed) {
            changed = false;
            // Search immediate neighbors of curr_obj at layer l
            let c_ptr = get_node_ptr(curr_obj);
            let r_ptr = c_ptr + 8;
            for(let k=0; k<l; k++) {
                let cnt = load<i32>(r_ptr);
                let cap = (k==0)?M_MAX0:M;
                r_ptr += 4 + <usize>cap*4;
            }
            let count = load<i32>(r_ptr);
            let n_ptr = r_ptr + 4;
            
            for(let i=0; i<count; i++) {
                let neighbor = load<i32>(n_ptr + <usize>i*4);
                let d = dist_l2_sq(target_vec_ptr, get_vector_ptr(neighbor));
                if (d < curr_dist) {
                    curr_dist = d;
                    curr_obj = neighbor;
                    changed = true;
                }
            }
        }
    }
    
    // Phase 2: From level down to 0, search and connect
    for (let l = (level < max_level ? level : max_level); l >= 0; l--) {
        // Use search_layer to find EF neighbors
        let candidates = search_layer(target_vec_ptr, curr_obj, l, EF_CONSTRUCTION);
        // Select neighbors (heuristic: just top M from candidates)
        let selected_count = 0;
        // Candidates are closest first. Take top M.
        for (let i = 0; i < candidates.size(); i++) {
            let cand = candidates.elements[i];
            add_connection(id, cand.id, l);
            add_connection(cand.id, id, l);
            selected_count++;
            if (selected_count >= M) break;
        }
        // Update curr_obj for next layer to be the closest found here
        if (candidates.size() > 0) {
            let best = candidates.popClosest();
            if (best) curr_obj = best.id;
        }
    }
    
    if (level > max_level) {
        max_level = level;
        entry_point_id = id;
    }
    element_count++;
}

export function get_results_ptr(): usize {
    return results_buffer_ptr;
}

export function search(query_vec_offset: usize, k: i32): i32 {
   if (entry_point_id == -1) return 0;
   
   let curr_obj = entry_point_id;
   let curr_dist = dist_l2_sq(query_vec_offset, get_vector_ptr(curr_obj));
   
   // Phase 1: Zoom in from top layers
   for (let l = max_level; l > 0; l--) {
       let changed = true;
       while(changed) {
           changed = false;
           let c_ptr = get_node_ptr(curr_obj);
           let r_ptr = c_ptr + 8;
           for(let k=0; k<l; k++) {
                let cnt = load<i32>(r_ptr);
                let cap = (k==0)?M_MAX0:M;
                r_ptr += 4 + <usize>cap*4;
           }
           let count = load<i32>(r_ptr);
           let n_ptr = r_ptr + 4;
           for(let i=0; i<count; i++) {
                let neighbor = load<i32>(n_ptr + <usize>i*4);
                let d = dist_l2_sq(query_vec_offset, get_vector_ptr(neighbor));
                if (d < curr_dist) {
                    curr_dist = d;
                    curr_obj = neighbor;
                    changed = true;
                }
           }
       }
   }
   
   // Phase 2: Layer 0 Search with EF (should be > k)
   let ef = (k > 50) ? k : 50;
   let results = search_layer(query_vec_offset, curr_obj, 0, ef);
   
   // Write results to buffer
   // Results in CandidateList are closest-first. We want top K.
   let count = results.size();
   let out_count = (count < k) ? count : k;
   
   for (let i = 0; i < out_count; i++) {
       let cand = results.elements[i];
       store<i32>(results_buffer_ptr + <usize>i * 8, cand.id);
       store<f32>(results_buffer_ptr + <usize>i * 8 + 4, cand.distance);
   }
   
   return out_count;
}
```

---

```assembly\index.ts
// Entry point for the WASM module

import {
	init_memory,
	alloc,
	get_memory_usage,
	set_memory_usage,
	reset_memory,
} from "./memory";
import { init_index, insert, search, get_results_ptr } from "./hnsw";
import { dist_l2_sq, dist_dot } from "./math";
import { update_config } from "./config";

export function set_config(dim: i32, m: i32, ef_construction: i32): void {
	update_config(dim, m, ef_construction);
}

// Re-export functions to be used by the host
export { init_memory, alloc, get_memory_usage, set_memory_usage, reset_memory };
export { init_index, insert, search, get_results_ptr };
export { dist_l2_sq, dist_dot };

// Optional: Test function to verify SIMD works
export function test_simd(ptr1: usize, ptr2: usize): f32 {
	return dist_l2_sq(ptr1, ptr2);
}

```

---

```assembly\math.ts
import { DIM } from "./config";

// Calculate L2 Distance Squared (Euclidean distance squared)
// Using SIMD for performance
export function dist_l2_sq(ptr1: usize, ptr2: usize): f32 {
	let sum: v128 = f32x4.splat(0);
	let i: i32 = 0;

	// Loop with SIMD (process 4 floats at a time)
	// Ensure DIM is a multiple of 4 in config
	while (i < DIM) {
		let v1: v128 = v128.load(ptr1 + <usize>(i * 4));
		let v2: v128 = v128.load(ptr2 + <usize>(i * 4));

		let diff: v128 = f32x4.sub(v1, v2);
		let sq: v128 = f32x4.mul(diff, diff);
		sum = f32x4.add(sum, sq);

		i += 4;
	}

	// Reduce sum: sum.x + sum.y + sum.z + sum.w
	// Using a more portable way for reduction
	// v128 is 128-bit, holding 4 f32s.

	// Extract lanes
	return (
		f32x4.extract_lane(sum, 0) +
		f32x4.extract_lane(sum, 1) +
		f32x4.extract_lane(sum, 2) +
		f32x4.extract_lane(sum, 3)
	);
}

// Calculate Dot Product
// Useful for Cosine Similarity (if vectors are normalized)
export function dist_dot(ptr1: usize, ptr2: usize): f32 {
	let sum: v128 = f32x4.splat(0);
	let i: i32 = 0;

	while (i < DIM) {
		let v1: v128 = v128.load(ptr1 + <usize>(i * 4));
		let v2: v128 = v128.load(ptr2 + <usize>(i * 4));

		let prod: v128 = f32x4.mul(v1, v2);
		sum = f32x4.add(sum, prod);

		i += 4;
	}

	return (
		f32x4.extract_lane(sum, 0) +
		f32x4.extract_lane(sum, 1) +
		f32x4.extract_lane(sum, 2) +
		f32x4.extract_lane(sum, 3)
	);
}

// L2 Distance for Int8 vectors
// Returns i32 squared distance
export function dist_l2_i8(ptr1: usize, ptr2: usize): i32 {
	let sum: v128 = i32x4.splat(0);
	let i: i32 = 0;

	// Process 16 bytes (int8) at a time if DIM is multiple of 16
	// Or 8 bytes if multiple of 8.
	// Assuming DIM is multiple of 16 for best speed.
	// If DIM=128, it fits perfectly.

	while (i < DIM) {
		// Load 16 x i8
		let v1 = v128.load(ptr1 + <usize>i);
		let v2 = v128.load(ptr2 + <usize>i);

		// Extending sub: (v1 - v2) -> i16
		// WASM SIMD has extmul but not simple ext_sub easily for all lanes without shuffling.
		// Better approach for L2 sq:
		// 1. AbsDiff: |a - b| (u8)
		// 2. Widen to i16
		// 3. Square
		// 4. Accumulate to i32

		// Sadly v128.sum_squares_diff doesn't exist directly.
		// We do: i16x8_extadd_pairwise_i8x16(v1, v2) ... complex.

		// Simpler implementation for now (loop unroll or smaller chunks):
		// Let's process 8 at a time to expand to i16 safely.

		// Strategy: Load 128-bit, unpack low/high to i16, sub, square, add.

		let v1_lo = i16x8.extend_low_i8x16(v1);
		let v1_hi = i16x8.extend_high_i8x16(v1);
		let v2_lo = i16x8.extend_low_i8x16(v2);
		let v2_hi = i16x8.extend_high_i8x16(v2);

		let diff_lo = i16x8.sub(v1_lo, v2_lo);
		let diff_hi = i16x8.sub(v1_hi, v2_hi);

		let sq_lo = i16x8.mul(diff_lo, diff_lo);
		let sq_hi = i16x8.mul(diff_hi, diff_hi);

		// Now we have i16 squares. We need to accumulate to i32 to avoid overflow (128*128*128 > 65535)
		// extend_low/high again from i16 to i32

		let sq_lo_lo = i32x4.extend_low_i16x8(sq_lo);
		let sq_lo_hi = i32x4.extend_high_i16x8(sq_lo);
		let sq_hi_lo = i32x4.extend_low_i16x8(sq_hi);
		let sq_hi_hi = i32x4.extend_high_i16x8(sq_hi);

		sum = i32x4.add(sum, sq_lo_lo);
		sum = i32x4.add(sum, sq_lo_hi);
		sum = i32x4.add(sum, sq_hi_lo);
		sum = i32x4.add(sum, sq_hi_hi);

		i += 16;
	}

	return (
		i32x4.extract_lane(sum, 0) +
		i32x4.extract_lane(sum, 1) +
		i32x4.extract_lane(sum, 2) +
		i32x4.extract_lane(sum, 3)
	);
}

```

---

```assembly\memory.ts
// Simple Linear Memory Manager (Slab Allocator)
// Purpose: Manage memory for HNSW graph nodes manually to avoid GC.

// Pointers are just u32 indices into Linear Memory

// Global bump pointer
// We start allocating after the heap base provided by the compiler
// Built-in global provided by AS compiler
// declare const __heap_base: usize; // Removed to prevent accidental import generation

let next_ptr: usize = 0;

export function init_memory(): void {
  // Align to 16 bytes
  // @ts-ignore: __heap_base is global
  next_ptr = (__heap_base + 15) & ~15;
}

// Allocate a block of size 'size' bytes
export function alloc(size: usize): usize {
  let ptr = next_ptr;
  // Align next pointer to 4 bytes
  let aligned_size = (size + 3) & ~3;
  let new_ptr = ptr + aligned_size;

  // Auto-grow memory if needed
  let current_pages = memory.size();
  let current_bytes = <usize>current_pages << 16;

  if (new_ptr > current_bytes) {
      let needed_bytes = new_ptr - current_bytes;
      // Calculate pages needed (ceil division)
      let needed_pages = (needed_bytes + 0xFFFF) >>> 16;
      // Grow memory
      memory.grow(<i32>needed_pages);
  }

  next_ptr = new_ptr;
  return ptr;
}

// Get current memory usage
// Returns the offset of the last used byte
export function get_memory_usage(): usize {
  return next_ptr;
}

// Set memory pointer (used during loading)
export function set_memory_usage(ptr: usize): void {
  next_ptr = ptr;
}

// Reset memory (DANGEROUS: Use only for testing or full clear)
export function reset_memory(): void {
  init_memory();
}
```

---

```assembly\pqueue.ts
// A specialized Candidate List for HNSW
// Maintains a sorted list of candidates (closest first)

export class Candidate {
    id: i32;
    distance: f32;
    
    constructor(id: i32, distance: f32) {
        this.id = id;
        this.distance = distance;
    }
}

// A static array wrapper to avoid GC if possible, but for v1 we use class for simplicity.
// We need to manage a list of candidates up to size 'capacity'.

export class CandidateList {
    elements: Candidate[];
    capacity: i32;

    constructor(capacity: i32) {
        this.capacity = capacity;
        this.elements = new Array<Candidate>(0);
    }

    // Add a candidate. Keep sorted (Ascending distance).
    // Returns true if added, false if rejected (worse than worst and full)
    push(id: i32, distance: f32): boolean {
        if (this.elements.length >= this.capacity) {
            // If full, check if new candidate is better than the worst (last)
            let worst = this.elements[this.elements.length - 1];
            if (distance >= worst.distance) {
                return false;
            }
        }

        // Insert in order
        // Binary search for position could be faster, but linear scan is fine for small N
        let inserted = false;
        for (let i = 0; i < this.elements.length; i++) {
            if (distance < this.elements[i].distance) {
                // Manual Insert (Splice replacement)
                // 1. Expand
                this.elements.push(new Candidate(0, 0.0)); // Placeholder
                // 2. Shift right
                for (let k = this.elements.length - 1; k > i; k--) {
                    this.elements[k] = this.elements[k - 1];
                }
                // 3. Set
                this.elements[i] = new Candidate(id, distance);
                inserted = true;
                break;
            }
        }
        if (!inserted) {
            this.elements.push(new Candidate(id, distance));
        }

        // Trim
        if (this.elements.length > this.capacity) {
            this.elements.pop();
        }
        return true;
    }

    // Get the closest (first)
    popClosest(): Candidate | null {
        if (this.elements.length == 0) return null;
        return this.elements.shift();
    }

    // Get current worst distance
    worstDist(): f32 {
        if (this.elements.length > 0) {
            return this.elements[this.elements.length - 1].distance;
        }
        return 99999999.0;
    }

    isEmpty(): boolean {
        return this.elements.length == 0;
    }
    
    size(): i32 {
        return this.elements.length;
    }
}
```

---

```assembly\tsconfig.json
{
	"extends": "../node_modules/assemblyscript/std/assembly.json",
	"include": ["**/*.ts"]
}

```

---

```assembly\types.ts
// Data Structures Layout

import { DIM, M, M_MAX0 } from "./config";

// We handle two main types of objects in memory:
// 1. Vectors (Raw Float32 Arrays)
// 2. Nodes (Graph Structure)

// --- VECTOR STORAGE ---
// Each vector is simply DIM * 4 bytes.
// Converted to function for dynamic configuration
export function get_vector_size(): usize {
    return <usize>DIM * 4;
}

// --- NODE STORAGE ---
// A node in HNSW needs to store:
// - id: i32 (External/Internal ID mapping is handled in JS, here we just store an int ID)
// - level: i32 (Highest level this node exists in)
// - neighbors: Array of pointers (offsets) for each level

// Memory Layout of a Node:
// [0-3]   id: i32
// [4-7]   level: i32
// [8...]  neighbors_data

// Neighbors Data Layout:
// For each level L from 0 to level:
//   [count: i32] (Number of neighbors at this level)
//   [n1, n2, ... nM]: i32 * M (Neighbor IDs)

// Since different nodes have different levels, the size is variable.
// We need a function to calculate size.

export function get_node_size(level: i32): usize {
    // Base size: id + level
    let size: usize = 8;

    // Level 0 has M_MAX0 neighbors
    // Levels 1..level have M neighbors
    
    // Level 0
    size += 4; // count
    size += <usize>M_MAX0 * 4; // neighbors

    // Level 1 to level
    if (level > 0) {
        let num_upper_layers = <usize>level;
        size += num_upper_layers * (4 + <usize>M * 4);
    }

    return size;
}
```

---

```src\api\server.ts
import Fastify, { FastifyInstance } from 'fastify';
import cors from '@fastify/cors';
import path from 'path';
import { MiniVectorDB } from '../index';

const server: FastifyInstance = Fastify({ logger: true });

// --- Global State ---
const db = new MiniVectorDB();
const DUMP_PATH = path.join(__dirname, '../../data/dump.bin');

// --- Interfaces ---
interface InsertBody {
    id: string;
    vector: number[];
    metadata?: any;
}

interface SearchBody {
    vector: number[];
    k?: number;
    filter?: any; // MongoDB-style filter for LokiJS
}

// --- Setup ---
async function start() {
    await server.register(cors, { origin: true });

    // 1. Initialize DB
    await db.init();

    // Try to load dump if exists
    try {
        await db.load(DUMP_PATH);
        server.log.info("Data loaded from dump.");
    } catch (e) {
        server.log.info("No dump found or load failed, starting fresh.");
    }

    // --- Routes ---

    // 1. Insert
    server.post<{ Body: InsertBody }>('/insert', async (request, reply) => {
        const { id, vector, metadata } = request.body;

        if (!id || !vector || vector.length !== 128) {
            return reply.code(400).send({ error: "Invalid input. Vector must be 128 dim." });
        }

        await db.insert({ id, vector, metadata });
        return { status: "ok" };
    });

    // 2. Search
    server.post<{ Body: SearchBody }>('/search', async (request, reply) => {
        const { vector, k = 10, filter } = request.body;

        if (!vector || vector.length !== 128) {
            return reply.code(400).send({ error: "Invalid vector" });
        }

        const f32Vec = new Float32Array(vector);

        // 1. If filter exists, pre-filter? 
        // Current WASM implementation doesn't support BitMask filter yet.
        // So we do Post-Filtering for v1.
        // Better strategy: Filter first, get allowed Internal IDs? 
        // But HNSW search needs to know forbidden nodes *during* traversal.
        // For now: Just search more (k * 5), then filter in JS.
        
        const searchK = filter ? k * 10 : k;
        const results = await db.search(f32Vec, k, filter);
        return { results };
    });

    // 3. Save
    server.post('/save', async (request, reply) => {
        await db.save(DUMP_PATH);
        return { status: "saved" };
    });
    
    // 4. Stats
    server.get('/stats', async () => {
        return db.getStats();
    });

    // Start
    const port = parseInt(process.env.PORT || '3000');
    try {
        await server.listen({ port, host: '0.0.0.0' });
        console.log(`Server listening at http://localhost:${port}`);
    } catch (err) {
        server.log.error(err);
        process.exit(1);
    }
}

start();
```

---

```src\core\wasm-bridge.ts
import fs from 'fs';
import loader from '@assemblyscript/loader';
import path from 'path';

const WASM_PATH = path.join(__dirname, '../../build/release.wasm');

export class WasmBridge {
  private wasmModule: any;
  private memory!: WebAssembly.Memory;
  private instance!: WebAssembly.Instance;
  
  // Pointers/Offsets
  private inputBufferPtr: number = 0;

  constructor() {
    // We will use the memory exported by WASM
  }

  async init(config?: { dim: number, m: number, ef: number }) {
    const wasmBuffer = fs.readFileSync(WASM_PATH);
    const imports = {
      env: {
        abort: (msg: number, file: number, line: number, col: number) => {
            console.error(`WASM Abort: ${line}:${col}`);
        },
        seed: () => Math.random(), // Required by AS Math.random()
      }
    };

    const result = await loader.instantiate(wasmBuffer, imports);
    this.wasmModule = result.exports;
    this.instance = result.instance;
    // Get the exported memory
    this.memory = this.wasmModule.memory as WebAssembly.Memory;
    
    this.wasmModule.init_memory();

    // Apply Config if provided
    if (config) {
        console.log("Applying WASM Config:", config);
        this.wasmModule.set_config(config.dim, config.m, config.ef);
    }

    // Initialize the index with capacity
    this.wasmModule.init_index(10000);
    
    console.log('WASM Initialized. Memory size:', this.memory.buffer.byteLength);
  }

  // Helper to write a float array to WASM memory
  // Returns the offset
  writeVector(vector: Float32Array): number {
     // In a real app, we would have a dedicated input buffer area in WASM
     // For now, we use a simple alloc from the module if exposed, or just 
     // poke into a known free area. 
     // A better way: Expose an 'alloc_input(size)' function in WASM.
     
     // Let's assume we added 'alloc' to exports in index.ts (we need to do that)
     const ptr = this.wasmModule.alloc(vector.length * 4);
     
     // Create a view on the memory
     const view = new Float32Array(this.memory.buffer, ptr, vector.length);
     view.set(vector);
     return ptr;
  }

  insert(id: number, vector: Float32Array) {
      const ptr = this.writeVector(vector);
      this.wasmModule.insert(id, ptr);
  }

  search(vector: Float32Array, k: number) {
      const ptr = this.writeVector(vector);
      // Now returns count of results found
      const count = this.wasmModule.search(ptr, k);
      
      if (count === 0) return [];

      const resultsPtr = this.wasmModule.get_results_ptr();
      const results = [];
      
      // Read from memory: [id(i32), dist(f32)]
      // We use DataView for safe endianness access, or typed array
      const view = new DataView(this.memory.buffer, resultsPtr, count * 8);
      
      for (let i = 0; i < count; i++) {
          const id = view.getInt32(i * 8, true); // true = little endian (WASM standard)
          const dist = view.getFloat32(i * 8 + 4, true);
          results.push({ id, dist });
      }
      
      return results;
  }

  async save(filepath: string) {
      const usedBytes = this.wasmModule.get_memory_usage();
      console.log(`Saving ${usedBytes} bytes to ${filepath}...`);
      
      // Create a view of the used memory
      const bufferView = new Uint8Array(this.memory.buffer, 0, usedBytes);
      await fs.promises.writeFile(filepath, bufferView);
      console.log("Saved.");
  }

  async load(filepath: string) {
      if (!fs.existsSync(filepath)) {
          console.log("No save file found.");
          return;
      }
      
      const buffer = await fs.promises.readFile(filepath);
      console.log(`Loading ${buffer.byteLength} bytes from ${filepath}...`);
      
      // Ensure WASM memory is large enough
      const currentSize = this.memory.buffer.byteLength;
      if (currentSize < buffer.byteLength) {
          const pagesNeeded = Math.ceil((buffer.byteLength - currentSize) / 65536);
          this.memory.grow(pagesNeeded);
      }
      
      // Copy data into WASM memory
      const wasmView = new Uint8Array(this.memory.buffer);
      wasmView.set(buffer);
      
      // Restore the memory allocator pointer
      this.wasmModule.set_memory_usage(buffer.byteLength);
      
      console.log("Loaded.");
  }
}
```

---

```src\embedder.ts
import {
	pipeline,
	RawImage,
	AutoProcessor,
	AutoTokenizer,
	CLIPTextModelWithProjection,
	CLIPVisionModelWithProjection,
} from "@xenova/transformers";
import fs from "fs";

export type ModelArchitecture = "text" | "clip";

/**
 * @zh-CN 本地嵌入模型包装类。
 * @en Local embedding model wrapper.
 */
export class LocalEmbedder {
	private pipe: any = null;
	private modelName: string;
	private architecture: ModelArchitecture;

	private processor: any = null;
	private tokenizer: any = null;
	private visionModel: any = null;
	private textModel: any = null;

	private initPromise: Promise<void> | null = null;

	constructor(modelName: string, architecture?: ModelArchitecture) {
		this.modelName = modelName;
		// 如果未指定架构，则根据名称猜测 (向后兼容)
		this.architecture =
			architecture ||
			(modelName.toLowerCase().includes("clip") ? "clip" : "text");
	}

	async init(): Promise<void> {
		if (this.initPromise) return this.initPromise;

		this.initPromise = (async () => {
			try {
				console.log(
					`Loading embedding model [${this.architecture}]: ${this.modelName}...`,
				);

				if (this.architecture === "clip") {
					const [p, t, v, tm] = await Promise.all([
						AutoProcessor.from_pretrained(this.modelName),
						AutoTokenizer.from_pretrained(this.modelName),
						CLIPVisionModelWithProjection.from_pretrained(this.modelName),
						CLIPTextModelWithProjection.from_pretrained(this.modelName),
					]);
					this.processor = p;
					this.tokenizer = t;
					this.visionModel = v;
					this.textModel = tm;
				} else {
					// @ts-ignore
					this.pipe = await pipeline("feature-extraction", this.modelName);
				}
				console.log("Model loaded successfully.");
			} catch (error) {
				this.initPromise = null;
				throw error;
			}
		})();

		return this.initPromise;
	}

	async embed(input: any): Promise<Float32Array> {
		await this.init();

		const isImageSrc =
			input instanceof Buffer ||
			input instanceof Uint8Array ||
			(typeof input === "string" &&
				(input.startsWith("http") || fs.existsSync(input)));

		// --- CLIP 多模态处理 ---
		if (this.architecture === "clip") {
			if (isImageSrc) {
				const image = await RawImage.read(input as any);
				const { pixel_values } = await this.processor(image);
				const { image_embeds } = await this.visionModel({ pixel_values });
				return this._normalize(image_embeds.data as Float32Array);
			} else {
				const inputs = await this.tokenizer(input, {
					padding: true,
					truncation: true,
				});
				const { text_embeds } = await this.textModel(inputs);
				return this._normalize(text_embeds.data as Float32Array);
			}
		}

		// --- 标准文本模型处理 ---
		const output = await this.pipe(input, { pooling: "mean", normalize: true });
		return output.data as Float32Array;
	}

	private _normalize(v: Float32Array): Float32Array {
		let normSq = 0;
		for (let i = 0; i < v.length; i++) normSq += v[i] * v[i];
		const norm = Math.sqrt(normSq);
		if (norm > 0) {
			for (let i = 0; i < v.length; i++) v[i] /= norm;
		}
		return v;
	}
}

```

---

```src\index.ts
import { WasmBridge } from "./core/wasm-bridge";
import { MetaDB } from "./storage/meta-db";
import { LocalEmbedder } from "./embedder";
import path from "path";

/**
 * @zh-CN 搜索结果项的接口定义。
 * @en Interface defining a search result item.
 */
export interface SearchResult {
	id: string;
	score: number;
	metadata: any;
}

/**
 * @zh-CN 插入项的接口定义。
 * @en Interface defining an item to be inserted.
 */
export interface InsertItem {
	id: string;
	/**
	 * @zh-CN 向量数据、文本或图片输入。
	 * @en Vector data, text, or image input.
	 */
	vector: number[] | Float32Array | string | Buffer | Uint8Array;
	metadata?: any;
}

/**
 * @zh-CN 数据库配置的接口定义。
 * @en Interface defining database configuration.
 */
export interface DBConfig {
	/**
	 * @zh-CN 向量维度
	 * @en Vector dimension.
	 */
	dim?: number;
	/**
	 * @zh-CN 嵌入模型名称。默认 'Xenova/all-MiniLM-L6-v2'。
	 */
	modelName?: string;
	/**
	 * @zh-CN 模型架构类型。
	 *         - 'text': 纯文本模型 (如 BERT, RoBERTa)
	 *         - 'clip': 图文多模态模型 (如 CLIP)
	 *         如果不提供，将根据 modelName 自动推断。
	 * @en Model architecture type.
	 *       - 'text': Pure text model (e.g., BERT, RoBERTa)
	 *       - 'clip': Multi-modal model (e.g., CLIP)
	 */
	modelArchitecture?: "text" | "clip";
	/**
	 * @zh-CN 每个节点在每层的最大连接数 (M)。默认 16。
	 */
	m?: number;
	/**
	 * @zh-CN 动态候选列表的大小 (efConstruction)。默认 100。
	 */
	ef_construction?: number;
	/**
	 * @zh-CN 元数据数据库文件的存储路径。
	 */
	metaDbPath?: string;
}

/**
 * @zh-CN MiniVectorDB 类，提供向量数据库的核心功能。
 */
export class MiniVectorDB {
	private wasm: WasmBridge;
	private meta: MetaDB;
	private embedder: LocalEmbedder;
	private config: DBConfig;
	private isReady: boolean = false;

	constructor(config: DBConfig = {}) {
		this.config = config;
		this.wasm = new WasmBridge();
		this.meta = new MetaDB(config.metaDbPath);
		this.embedder = new LocalEmbedder(
			config.modelName || "Xenova/all-MiniLM-L6-v2",
			config.modelArchitecture,
		);
	}

	async init() {
		if (this.isReady) return;

		const wasmConfig = {
			dim: this.config.dim || 384,
			m: this.config.m || 16,
			ef: this.config.ef_construction || 100,
		};

		await this.wasm.init(wasmConfig);
		await this.meta.ready();
		this.isReady = true;
	}

	async insert(item: InsertItem): Promise<void> {
		if (!this.isReady) await this.init();
		const { id, vector, metadata } = item;
		let f32Vec: Float32Array;

		if (
			typeof vector === "string" ||
			vector instanceof Buffer ||
			vector instanceof Uint8Array
		) {
			f32Vec = await this.embedder.embed(vector);
		} else if (vector instanceof Float32Array) {
			f32Vec = vector;
		} else {
			f32Vec = new Float32Array(vector);
		}

		const expectedDim = this.config.dim || 384;
		if (f32Vec.length !== expectedDim) {
			throw new Error(
				`Vector dimension mismatch. Expected ${expectedDim}, got ${f32Vec.length}`,
			);
		}

		let internalId = -1;
		const existing = this.meta.get(id);
		if (existing) {
			internalId = existing.internal_id;
			this.meta.add(id, internalId, metadata || existing.metadata);
		} else {
			internalId = this.meta.items.count();
			this.meta.add(id, internalId, metadata || {});
		}

		this.wasm.insert(internalId, f32Vec);
	}

	async search(
		query: number[] | Float32Array | string | Buffer | Uint8Array,
		k: number = 10,
		filter?: any,
	): Promise<SearchResult[]> {
		if (!this.isReady) await this.init();
		let f32Vec: Float32Array;

		if (
			typeof query === "string" ||
			query instanceof Buffer ||
			query instanceof Uint8Array
		) {
			f32Vec = await this.embedder.embed(query);
		} else if (query instanceof Float32Array) {
			f32Vec = query;
		} else {
			f32Vec = new Float32Array(query);
		}

		const searchK = filter ? k * 10 : k;
		const rawResults = this.wasm.search(f32Vec, searchK);
		const results: SearchResult[] = [];

		for (const res of rawResults) {
			const item = this.meta.getByInternalId(res.id);
			if (!item) continue;

			if (filter) {
				let match = true;
				for (const key in filter) {
					if (item.metadata[key] !== filter[key]) {
						match = false;
						break;
					}
				}
				if (!match) continue;
			}

			results.push({
				id: item.external_id,
				score: res.dist,
				metadata: item.metadata,
			});

			if (results.length >= k) break;
		}
		return results;
	}

	async save(filepath: string) {
		await this.wasm.save(filepath);
	}

	async load(filepath: string) {
		if (!this.isReady) await this.init();
		await this.wasm.load(filepath);
	}

	getStats() {
		return {
			memory: this.wasm["memory"].buffer.byteLength,
			items: this.meta.items.count(),
		};
	}

	async close() {
		await this.meta.close();
	}
}

```

---

```src\storage\meta-db.ts
import Loki from 'lokijs';
import path from 'path';
import fs from 'fs';

interface Item {
    external_id: string;
    internal_id: number;
    metadata: any;
}

export class MetaDB {
    items!: Collection<Item>;
    private db: Loki;
    private dbPath: string;

    constructor(dbPath: string = path.join(__dirname, '../../data/metadata.json')) {
        this.dbPath = dbPath;
        
        // Ensure directory exists
        const dir = path.dirname(dbPath);
        if (!fs.existsSync(dir)) {
            fs.mkdirSync(dir, { recursive: true });
        }

        this.db = new Loki(dbPath, {
            autoload: true,
            autoloadCallback: this.initCollection.bind(this),
            autosave: true,
            autosaveInterval: 4000
        });
    }

    private initCollection() {
        let items = this.db.getCollection<Item>('items');
        if (items === null) {
            items = this.db.addCollection<Item>('items', {
                indices: ['external_id', 'internal_id']
            });
        }
        this.items = items;
        console.log('MetaDB initialized with', this.items.count(), 'items');
    }

    // Wait for DB to load if needed (LokiJS autoload is async-ish)
    // For this simple example we assume it loads fast or we wrap usage.
    // A robust way involves a Promise.
    async ready(): Promise<void> {
        return new Promise((resolve) => {
            if (this.db.persistenceAdapter) {
                 // already loaded or loading
                 resolve(); // Simplified
                 return;
            }
            // Force save to trigger callback or just wait logic
            // LokiJS autoload is tricky in sync constructor. 
            // Let's manually load.
            this.db.loadDatabase({}, () => {
                this.initCollection();
                resolve();
            });
        });
    }

    add(externalId: string, internalId: number, metadata: any) {
        if (!this.items) this.initCollection();
        
        const existing = this.items.findOne({ external_id: externalId });
        if (existing) {
            existing.internal_id = internalId;
            existing.metadata = metadata;
            this.items.update(existing);
        } else {
            this.items.insert({ external_id: externalId, internal_id: internalId, metadata });
        }
    }

    get(externalId: string): Item | null {
        if (!this.items) return null;
        return this.items.findOne({ external_id: externalId });
    }

    getByInternalId(internalId: number): Item | null {
        if (!this.items) return null;
        return this.items.findOne({ internal_id: internalId });
    }

    // Filter example: Find internal IDs where metadata.type == 'article'
    filter(query: any): number[] {
        if (!this.items) return [];
        // LokiJS query syntax
        const results = this.items.find(query);
        return results.map(r => r.internal_id);
    }

    close(): Promise<void> {
        return new Promise((resolve) => {
            this.db.close(resolve);
        });
    }
}
```

---

```asconfig.json
{
	"targets": {
		"debug": {
			"outFile": "build/debug.wasm",
			"textFile": "build/debug.wat",
			"sourceMap": true,
			"debug": true
		},
		"release": {
			"outFile": "build/release.wasm",
			"textFile": "build/release.wat",
			"sourceMap": false,
			"optimizeLevel": 3,
			"shrinkLevel": 1,
			"converge": false,
			"noAssert": true,
			"enable": ["simd"],
			"initialMemory": 100,
			"maximumMemory": 32768
		}
	},
	"options": {}
}

```

---

```tests\persistence_test.ts
import { MiniVectorDB } from "../src/index";
import path from "path";
import fs from "fs";

const DUMP_PATH = path.join(process.cwd(), "data/persistence_dump");
const META_PATH = path.join(process.cwd(), "data/persistence_meta.json");

async function main() {
	console.log("--- PERSISTENCE TEST START ---");

	// Clean up
	if (fs.existsSync(DUMP_PATH)) fs.unlinkSync(DUMP_PATH);
	if (fs.existsSync(META_PATH)) fs.unlinkSync(META_PATH);

	// 1. Save data
	console.log("Stage 1: Inserting and Saving...");
	const db1 = new MiniVectorDB({ metaDbPath: META_PATH });
	await db1.init();

	// Use a unique vector to ensure search accuracy
	const vec = new Array(384).fill(0).map((_, i) => i / 384);
	await db1.insert({
		id: "persist-1",
		vector: vec,
		metadata: { info: "saved" },
	});

	await db1.save(DUMP_PATH);
	await db1.close();
	console.log("Data saved and DB closed.");

	// 2. Load data
	console.log("\nStage 2: Loading and Verifying...");
	const db2 = new MiniVectorDB({ metaDbPath: META_PATH });
	await db2.init();
	await db2.load(DUMP_PATH);

	// Important: check if meta load worked
	console.log(`MetaDB has ${db2.getStats().items} items.`);

	const results = await db2.search(vec, 1);
	console.log("Loaded Search Results:", JSON.stringify(results, null, 2));

	if (results.length > 0 && results[0].id === "persist-1") {
		console.log("✅ PERSISTENCE TEST PASSED");
	} else {
		console.error("❌ PERSISTENCE TEST FAILED: Result mismatch or empty");
		process.exit(1);
	}

	await db2.close();
}

main().catch((e) => {
	console.error(e);
	process.exit(1);
});

```
